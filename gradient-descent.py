import numpy as np


def gradient_descent(

    gradient, x, y, start, learn_rate=0.1, n_iter=50, tolerance=1e-06,

    dtype="float64"

):

    # Checking if the gradient is callable

    if not callable(gradient):

        raise TypeError("'gradient' must be callable")


    # Setting up the data type for NumPy arrays

    dtype_ = np.dtype(dtype)


    # Converting x and y to NumPy arrays

    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)

    if x.shape[0] != y.shape[0]:

        raise ValueError("'x' and 'y' lengths do not match")


    # Initializing the values of the variables

    vector = np.array(start, dtype=dtype_)


    # Setting up and checking the learning rate

    learn_rate = np.array(learn_rate, dtype=dtype_)

    if np.any(learn_rate <= 0):

        raise ValueError("'learn_rate' must be greater than zero")


    # Setting up and checking the maximal number of iterations

    n_iter = int(n_iter)

    if n_iter <= 0:

        raise ValueError("'n_iter' must be greater than zero")


    # Setting up and checking the tolerance

    tolerance = np.array(tolerance, dtype=dtype_)

    if np.any(tolerance <= 0):

        raise ValueError("'tolerance' must be greater than zero")


    # Performing the gradient descent loop

    for _ in range(n_iter):

        # Recalculating the difference

        diff = -learn_rate * np.array(gradient(x, y, vector), dtype_)


        # Checking if the absolute difference is small enough

        if np.all(np.abs(diff) <= tolerance):

            break


        # Updating the values of the variables

        vector += diff


    return vector if vector.shape else vector.item()